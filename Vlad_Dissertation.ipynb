{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82321c30",
   "metadata": {},
   "source": [
    "Parts of this code were adapted from Paredes et al., 2022 and certain parameter values were taken from Serino et al., 2015 or Magosso et al., 2010b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ee07f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_699/1247435164.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pylab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import differential_evolution\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import string\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e9403",
   "metadata": {},
   "source": [
    "# Network structure\n",
    "Variables that define the structure of the network model in the following terms:\n",
    "- dimensions of the encoded space, \n",
    "- number of neurons, \n",
    "- receptive fields (RF) centres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34d6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tactile area\n",
    "# Tactile area dimensions (cm)\n",
    "xt = 20\n",
    "yt = 10\n",
    "\n",
    "# Tactile neurons (count)\n",
    "Mt = 40  # Mt = 40 in Magosso2010b\n",
    "Nt = 20  # Nt = 20 in Magosso2010b\n",
    "\n",
    "# Tactile RF centres (cm)\n",
    "xrft = np.arange(1, Mt + 1) * 0.5 - 0.25\n",
    "yrft = np.arange(1, Nt + 1) * 0.5 - 0.25\n",
    "\n",
    "## Auditory area\n",
    "# Auditory area dimensions (cm)\n",
    "xa = 200\n",
    "ya = 30\n",
    "\n",
    "# Auditory neurons (count)\n",
    "Ma = 20\n",
    "Na = 3\n",
    "\n",
    "# Auditory RF centres (cm)\n",
    "xrfa = np.arange(1, Ma + 1) * 10 - 5\n",
    "yrfa = np.arange(1, Na + 1) * 10 - 15\n",
    "\n",
    "## Visual area\n",
    "# Visual area dimensions (cm)\n",
    "xv = 100\n",
    "yv = 15\n",
    "\n",
    "xtool = 85  # or 95\n",
    "\n",
    "# Visual neurons (count)\n",
    "Mv = 100\n",
    "Nv = 15\n",
    "\n",
    "# Visual RF centres (cm)\n",
    "xrfv = np.arange(1, Mv + 1) - 0.5  # As per Magosso2010b\n",
    "yrfv = np.arange(1, Nv + 1) - 3  # As per Magosso2010b\n",
    "\n",
    "dx = 0.2\n",
    "dy = 0.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c81fe76",
   "metadata": {},
   "source": [
    "# Network fixed parameters\n",
    "Variables that define the values of the parameters that remain fixed in our study. These parameters are related to: \n",
    "- the RF of the unisensory neurons,\n",
    "- the activation functions of both unisensory and multisensory neurons, \n",
    "- the visual and tactile stimuli that is administered during the experiment simulation and training simulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5549bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model fixed parameters for simulation/experiment setting\n",
    "# Question for Renato - why is ya_0 = 5, rather than 15?\n",
    "\n",
    "## Unisensory receptive fields\n",
    "phit_0 = 1  # Magosso2010b\n",
    "sigmat_phi = 0.5  # Magosso2010b\n",
    "\n",
    "phia_0 = 1  # Serino2015\n",
    "sigmaa_phi = 10  # Serino2015\n",
    "\n",
    "phiv_0 = 1  # Magosso2010b\n",
    "sigmav_phi = 1  # Magosso2010b\n",
    "\n",
    "## Neuronal activity\n",
    "\n",
    "# Tactile neurons\n",
    "fmin_t = -0.12\n",
    "fmax_t = 1\n",
    "qc_t = 19.43\n",
    "r_t = 0.34\n",
    "\n",
    "# Auditory neurons\n",
    "fmin_a = -0.12\n",
    "fmax_a = 1\n",
    "qc_a = 19.43\n",
    "r_a = 0.34\n",
    "\n",
    "# Visual neurons\n",
    "fmin_v = -0.12\n",
    "fmax_v = 1\n",
    "qc_v = 19.43\n",
    "r_v = 0.34\n",
    "\n",
    "# Multisensory neuron\n",
    "fmin_m = 0\n",
    "fmax_m = 1\n",
    "qc_m = 19.43\n",
    "r_m = 0.34\n",
    "\n",
    "tau = 20\n",
    "\n",
    "## External stimuli - Experimental Setting\n",
    "# Tactile stimuli\n",
    "It_0_exp = 2.5\n",
    "sigt_exp = 0.3\n",
    "yt_0_exp = 5  # cm\n",
    "xt_0_exp = 10  # cm\n",
    "\n",
    "# Auditory stimuli\n",
    "Ia_0_exp = 3.6\n",
    "siga_exp = 0.3\n",
    "ya_0_exp = 5  # cm\n",
    "xa_0_exp = 100  # cm\n",
    "\n",
    "# Visual Stimuli:\n",
    "# Participant is blindfolded during experimental setting - no visual stimulus\n",
    "\n",
    "# Gaussian noise\n",
    "\n",
    "signoise_t = 0\n",
    "signoise_a = 0\n",
    "\n",
    "stdnoise = 1\n",
    "\n",
    "## External stimuli - Training Setting\n",
    "# Tactile stimuli\n",
    "It_0_tr = 0.56\n",
    "sigtx_tr = 0.75\n",
    "sigty_tr = 1.25\n",
    "\n",
    "# Auditory stimuli\n",
    "Ia_0_tr = 0.0125\n",
    "sigax_tr = 3.75\n",
    "sigay_tr = 6\n",
    "\n",
    "# Visual Stimuli:\n",
    "Iv_0_tr = 0.121\n",
    "sigvx_tr = 3.75\n",
    "sigvy_tr = 6\n",
    "\n",
    "# Gaussian noise - training auditory and visual stimuli are much more noisy than before\n",
    "\n",
    "signoiset_t = 0  # 0.01\n",
    "signoiset_a = 0  # 0.2\n",
    "signoiset_v = 0  # 0.3\n",
    "\n",
    "stdnoise = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eddf83",
   "metadata": {},
   "source": [
    "# External stimuli functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a548bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## External stimulus - experiment run\n",
    "\n",
    "\n",
    "def stimspace_exp(s, x0, y0):\n",
    "    \"\"\"Compute the stimulus intensity for the unimodal space s (t/a) for a stimulus centered around x0 and y0. This stimulus is specifically related to\n",
    "    the experimental setting, which exlusively utilises audio-tactile information.\n",
    "\n",
    "    Input:\n",
    "        s  (char): region of stimulation (tactile/auditory)\n",
    "        x0 (int):  center point on the x axis of the stimulus\n",
    "        y0 (int):  center point on the y axis of the stimulus\n",
    "\n",
    "    Output:\n",
    "        v (2D.np.array): matrix of stimulus intensity for the entire unimodal space\n",
    "    \"\"\"\n",
    "\n",
    "    if s == \"t\":\n",
    "        a = np.reshape(\n",
    "            np.repeat(np.arange(0, xt + dx, dx), int(yt / dy + 1)),\n",
    "            (int(xt / dx + 1), int(yt / dy + 1)),\n",
    "        )\n",
    "        b = np.reshape(\n",
    "            np.tile(np.arange(0, yt + dx, dx), (int(xt / dx + 1))),\n",
    "            (int(xt / dx + 1), int(yt / dy + 1)),\n",
    "        )\n",
    "\n",
    "        v = (\n",
    "            np.ones((int(xt / dx + 1), int(yt / dy + 1))) * It_0_exp\n",
    "            + np.ones((int(xt / dx + 1), int(yt / dy + 1)))\n",
    "            * signoise_t\n",
    "            * np.random.randn()\n",
    "        ) * np.exp(\n",
    "            -(\n",
    "                np.square(np.ones((int(xt / dx + 1), int(yt / dy + 1))) * x0 - a)\n",
    "                + np.square(np.ones((int(xt / dx + 1), int(yt / dy + 1))) * y0 - b)\n",
    "            )\n",
    "            / (2 * np.square(sigt_exp))\n",
    "        )\n",
    "    else:\n",
    "        a = np.reshape(\n",
    "            np.repeat(np.arange(0, xa + dx, dx), int(ya / dy + 1)),\n",
    "            (int(xa / dx + 1), int(ya / dy + 1)),\n",
    "        )\n",
    "        b = np.reshape(\n",
    "            np.tile(np.arange(0, ya + dx, dx), (int(xa / dx + 1))),\n",
    "            (int(xa / dx + 1), int(ya / dy + 1)),\n",
    "        )\n",
    "\n",
    "        v = (\n",
    "            np.ones((int(xa / dx + 1), int(ya / dy + 1))) * Ia_0_exp\n",
    "            + np.ones((int(xa / dx + 1), int(ya / dy + 1)))\n",
    "            * signoise_a\n",
    "            * np.random.randn()\n",
    "        ) * np.exp(\n",
    "            -(\n",
    "                np.square(np.ones((int(xa / dx + 1), int(ya / dy + 1))) * x0 - a)\n",
    "                + np.square(np.ones((int(xa / dx + 1), int(ya / dy + 1))) * y0 - b)\n",
    "            )\n",
    "            / (2 * np.square(siga_exp))\n",
    "        )\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf6275",
   "metadata": {},
   "source": [
    "# Receptive fields functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e10bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF formula\n",
    "\n",
    "\n",
    "def phi(s, x, y):\n",
    "    \"\"\"Obtain the RF of the unimodality s (t/a/v) for a given set of spatial coordinates.\n",
    "\n",
    "    Input:\n",
    "        s (char): unimodality (t/a/v)\n",
    "        x (int): Spatial coordinate in the x-axis (cm).\n",
    "        y (int): Spatial coordinate in the y-axis (cm).\n",
    "\n",
    "    Output:\n",
    "        phi (2D.np.array): RF of the unimodality for the given spatial coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the RF matrix\n",
    "    if s == \"t\":\n",
    "        phi = np.zeros((Mt, Nt))\n",
    "\n",
    "        # Compute the RF for the tactile space on the given spatial coordinates\n",
    "        for i in range(Mt):\n",
    "            for j in range(Nt):\n",
    "                phi[i, j] = phit_0 * np.exp(\n",
    "                    -(\n",
    "                        (np.square(xrft[i] - x) + np.square(yrft[j] - y))\n",
    "                        / (2 * np.square(sigmat_phi))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    elif s == \"a\":\n",
    "        phi = np.zeros((Ma, Na))\n",
    "\n",
    "        # Compute the RF for the auditory space on the given spacial coordinates\n",
    "        for i in range(Ma):\n",
    "            for j in range(Na):\n",
    "                phi[i, j] = phia_0 * np.exp(\n",
    "                    -(\n",
    "                        (np.square(xrfa[i] - x) + np.square(yrfa[j] - y))\n",
    "                        / (2 * np.square(sigmaa_phi))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    else:\n",
    "        phi = np.zeros((Mv, Nv))\n",
    "\n",
    "        # Compute the RF for the visual space on the given spatial coordinates\n",
    "        for i in range(Mv):\n",
    "            for j in range(Nv):\n",
    "                phi[i][j] = phiv_0 * np.exp(\n",
    "                    -(\n",
    "                        (np.square(xrfv[i] - x) + np.square(yrfv[j] - y))\n",
    "                        / (2 * np.square(sigmav_phi))\n",
    "                    )\n",
    "                )\n",
    "    return phi\n",
    "\n",
    "\n",
    "def PhiRF(s):\n",
    "    \"\"\"Compute the RF of the unisensory areas for the discreteised spatial coordinates in the auditory and tactile spaces.\n",
    "    I run this once and then save the RFs as they do not change.\n",
    "\n",
    "    Input:\n",
    "        s (char): the unimodal region of interest (t/a/v)\n",
    "\n",
    "    Output:\n",
    "        Phi (4D np.array): RF of the area for the discretised spatial coordinates in the space.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the discretised spatial coordinates\n",
    "    if s == \"t\":\n",
    "        xl = xt\n",
    "        yn = yt\n",
    "        Phi = np.zeros((Mt, Nt, int(xt / dx + 1), int(yt / dy + 1)))\n",
    "\n",
    "    elif s == \"a\":\n",
    "        xl = xa\n",
    "        yn = ya\n",
    "        Phi = np.zeros((Ma, Na, int(xa / dx + 1), int(ya / dy + 1)))\n",
    "\n",
    "    else:\n",
    "        xl = xv\n",
    "        yn = yv\n",
    "        Phi = np.zeros((Mv, Nv, int(xv / dx + 1), int(yv / dy + 1)))\n",
    "\n",
    "    for k in range(int(xl / dx + 1)):\n",
    "        for l in range(int(yn / dy + 1)):\n",
    "            Phi[:, :, k, l] = phi(s, k * dx, l * dy)\n",
    "\n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65f236ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you do no thave access to these numpy objects already\n",
    "\n",
    "# Phit = PhiRF(\"t\")\n",
    "# Phia = PhiRF(\"a\")\n",
    "# Phiv = PhiRF(\"v\")\n",
    "\n",
    "# np.save(\"drafts/Phit.npy\", Phit)\n",
    "# np.save(\"drafts/Phia.npy\", Phia)\n",
    "# np.save(\"drafts/Phiv.npy\", Phiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc54bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phit = np.load(\"drafts/Phit.npy\")\n",
    "Phia = np.load(\"drafts/Phia.npy\")\n",
    "Phiv = np.load(\"drafts/Phiv.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69577fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PHI_expa(s, x0, y0):\n",
    "    \"\"\"This function computes the external input to the unimodal area \"s\" based on a stimulus centered around x0 and y0\n",
    "    Input:\n",
    "        s (char): unimodality (a/t)\n",
    "        x0 (int): center of the external stimulus on the x axis\n",
    "        y0 (int): center of the external stimulus on the y axis\n",
    "\n",
    "    Assumed Inputs:\n",
    "        Phit (4D.np.array): a matrix of each tactile neuron's receptive field\n",
    "        Phia (4D.np.array): a matrix of each auditory neuron's receptive field\n",
    "    \"\"\"\n",
    "\n",
    "    PHI = np.sum(np.multiply(Phia, stimspace_exp(s, x0, y0)), (3, 2))\n",
    "\n",
    "    return PHI\n",
    "\n",
    "\n",
    "def PHI_expt(s, x0, y0):\n",
    "    \"\"\"This function computes the external input to the unimodal area \"s\" based on a stimulus centered around x0 and y0\n",
    "    Input:\n",
    "        s (char): unimodality (a/t)\n",
    "        x0 (int): center of the external stimulus on the x axis\n",
    "        y0 (int): center of the external stimulus on the y axis\n",
    "\n",
    "    Assumed Inputs:\n",
    "        Phit (4D.np.array): a matrix of each tactile neuron's receptive field\n",
    "        Phia (4D.np.array): a matrix of each auditory neuron's receptive field\n",
    "    \"\"\"\n",
    "\n",
    "    PHI = np.sum(np.multiply(Phit, stimspace_exp(s, x0, y0)), (3, 2))\n",
    "\n",
    "    return PHI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12582936",
   "metadata": {},
   "source": [
    "# Synapses functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c39aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lw(\n",
    "    Lex_t,\n",
    "    Lin_t,\n",
    "    sigmaex_t,\n",
    "    sigmain_t,\n",
    "    Lex_a,\n",
    "    Lin_a,\n",
    "    sigmaex_a,\n",
    "    sigmain_a,\n",
    "    Lex_v,\n",
    "    Lin_v,\n",
    "    sigmaex_v,\n",
    "    sigmain_v,\n",
    "):\n",
    "    \"\"\"Compute the matrix of lateral connections (akin to a Mexican Hat Function). Still have not decided on the border effects.\n",
    "\n",
    "    Input:\n",
    "        Lex_t (int): the excitatory amplitude for the tactile lateral synapses\n",
    "        sigmaex_t (int): the excitatory spread for the tactile lateral synapses\n",
    "        Lin_t (int): the inhibitory amplitude for the tactile synapses\n",
    "        sigmain_t (int): the inhibitory spread for the tactile synapses\n",
    "\n",
    "        Lex_a (int): the excitatory amplitude for the auditory lateral synapses\n",
    "        sigmaex_a (int): the excitatory spread for the auditory lateral synapses\n",
    "        Lin_a (int): the inhibitory amplitude for the auditory synapses\n",
    "        sigmain_a (int): the inhibitory spread for the auditory synapses\n",
    "\n",
    "        Lex_v (int): the excitatory amplitude for the visual lateral synapses\n",
    "        sigmaex_v (int): the excitatory spread for the visual lateral synapses\n",
    "        Lin_v (int): the inhibitory amplitude for the visual synapses\n",
    "        sigmain_v (int): the inhibitory spread for the visual synapses\n",
    "\n",
    "    Output:\n",
    "        Lt (4D.np.array): the map of tactile lateral connections for each neuron (each ij position has a matrix detailing its connections with all neurons)\n",
    "        La (4D.np.array): the map of auditory lateral connections for each neuron (each ij position has a matrix detailing its connections with all neurons)\n",
    "        Lv (4D.np.array): the map of visual lateral connections for each neuron (each ij position has a matrix detailing its connections with all neurons)\n",
    "    \"\"\"\n",
    "    # Tactile recurrent connections\n",
    "\n",
    "    # calculate Dx and Dy using matrix operations\n",
    "\n",
    "    Lt = Lex_t * np.exp(\n",
    "        -(\n",
    "            np.square(xrft[:, None, None, None] - xrft[None, None, :, None])\n",
    "            + np.square(yrft[None, :, None, None] - yrft[None, None, None, :])\n",
    "        )\n",
    "        / (2 * sigmaex_t**2)\n",
    "    ) - Lin_t * np.exp(\n",
    "        -(\n",
    "            np.square(xrft[:, None, None, None] - xrft[None, None, :, None])\n",
    "            + np.square(yrft[None, :, None, None] - yrft[None, None, None, :])\n",
    "        )\n",
    "        / (2 * sigmain_t**2)\n",
    "    )\n",
    "    La = Lex_a * np.exp(\n",
    "        -(\n",
    "            np.square(xrfa[:, None, None, None] - xrfa[None, None, :, None])\n",
    "            + np.square(yrfa[None, :, None, None] - yrfa[None, None, None, :])\n",
    "        )\n",
    "        / (2 * sigmaex_a**2)\n",
    "    ) - Lin_a * np.exp(\n",
    "        -(\n",
    "            np.square(xrfa[:, None, None, None] - xrfa[None, None, :, None])\n",
    "            + np.square(yrfa[None, :, None, None] - yrfa[None, None, None, :])\n",
    "        )\n",
    "        / (2 * sigmain_a**2)\n",
    "    )\n",
    "    Lv = Lex_v * np.exp(\n",
    "        -(\n",
    "            np.square(xrfv[:, None, None, None] - xrfv[None, None, :, None])\n",
    "            + np.square(yrfv[None, :, None, None] - yrfv[None, None, None, :])\n",
    "        )\n",
    "        / (2 * sigmaex_v**2)\n",
    "    ) - Lin_v * np.exp(\n",
    "        -(\n",
    "            np.square(xrfv[:, None, None, None] - xrfv[None, None, :, None])\n",
    "            + np.square(yrfv[None, :, None, None] - yrfv[None, None, None, :])\n",
    "        )\n",
    "        / (2 * sigmain_v**2)\n",
    "    )\n",
    "\n",
    "    Lt = np.where(Lt == np.max(Lt), 0, Lt)\n",
    "    La = np.where(La == np.max(La), 0, La)\n",
    "    Lv = np.where(Lv == np.max(Lv), 0, Lv)\n",
    "\n",
    "    return Lt, La, Lv\n",
    "\n",
    "\n",
    "def FwFb(Wt_0, Wa_0, Wv_0, Bt_0, Ba_0, Bv_0, k1, k2, lim, alpha):\n",
    "    \"\"\"Feedforward and feedback synaptic weights of the unisensory neurons.\n",
    "\n",
    "    Args:\n",
    "        Wt_0 (int): Maximum value of the feedforward synapses in the tactile area.\n",
    "        Wa_0 (int): Maximum value of the feedforward synapses in the auditory area.\n",
    "        Wv_0 (int): Maximum value of the feedforward synapses in the visual area.\n",
    "\n",
    "        Bt_0 (int): Maximum value of the feedback synapses in the tactile area.\n",
    "        Ba_0 (int): Maximum value of the feedback synapses in the auditory area.\n",
    "        Bv_0 (int): Maximum value of the feedback synapses in the visual area.\n",
    "\n",
    "        k1 (int): Fast decay rate.\n",
    "        k2 (int): Slow decay rate.\n",
    "        lim (int): Boundary of the space on and near the hand.\n",
    "        alpha (int): Relative amplitude of each exponential.\n",
    "\n",
    "    Returns:\n",
    "        Wt (2D np.array): Feedforward synaptic weights in the tactile area.\n",
    "        Wa (2D np.array): Feedforward synaptic weights in the auditory area.\n",
    "        Wv (2D np.array): Feedforward synaptic weights in the visual area.\n",
    "\n",
    "        Bt (2D np.array): Feedback synaptic weights in the tactile area.\n",
    "        Ba (2D np.array): Feedback synaptic weights in the auditory area.\n",
    "        Bv (2D np.array): Feedback synaptic weights in the visual area.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build the feedforward and feedback synapses matrices\n",
    "\n",
    "    Bt = np.ones((Mt, Nt)) * Bt_0  # tactile feedback synapses identical\n",
    "    Wt = np.ones((Mt, Nt)) * Wt_0  # tactile feedback synapses identical\n",
    "\n",
    "    Ba = np.zeros((Ma, Na))\n",
    "    Wa = np.zeros((Ma, Na))\n",
    "\n",
    "    Bv = np.zeros((Mv, Nv))\n",
    "    Wv = np.zeros((Mv, Nv))\n",
    "\n",
    "    # Compute the feedforward and feedback synapses in the auditory area\n",
    "    for i in range(Ma):\n",
    "        for j in range(Na):\n",
    "            if xrfa[i] < lim:\n",
    "                D = 0\n",
    "            else:\n",
    "                D = np.linalg.norm(xrfa[i] - lim)\n",
    "\n",
    "            Ba[i, j] = alpha * Ba_0 * np.exp(-D / k1) + (1 - alpha) * Ba_0 * np.exp(\n",
    "                -D / k2\n",
    "            )\n",
    "            Wa[i, j] = alpha * Wa_0 * np.exp(-D / k1) + (1 - alpha) * Wa_0 * np.exp(\n",
    "                -D / k2\n",
    "            )\n",
    "\n",
    "    # Compute the feedforward and feedback synapses in the visual area\n",
    "    for i in range(Mv):\n",
    "        for j in range(Nv):\n",
    "            if xrfv[i] < lim:\n",
    "                D = 0\n",
    "            else:\n",
    "                D = np.linalg.norm(xrfv[i] - lim)\n",
    "\n",
    "            Bv[i, j] = alpha * Bv_0 * np.exp(-D / k1) + (1 - alpha) * Bv_0 * np.exp(\n",
    "                -D / k2\n",
    "            )\n",
    "            Wv[i, j] = alpha * Wv_0 * np.exp(-D / k1) + (1 - alpha) * Wv_0 * np.exp(\n",
    "                -D / k2\n",
    "            )\n",
    "\n",
    "    return Wt, Wa, Wv, Bt, Ba, Bv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69af2ca0",
   "metadata": {},
   "source": [
    "# Cross Modal Synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8edded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossmodal(at, sigat, vt, sigvt, av, sigav):\n",
    "    \"\"\"Create the crossmodal synapses across all unimodal regions. These synapses act similarly to the lateral connections.\n",
    "    They mimic a mexican hat function, having an excitatory peak, followed by  inhibitory surroundings.\n",
    "\n",
    "    Input:\n",
    "    at (int): strength of the excitatory Gaussian for the audiotactile connections\n",
    "    sigat (int): spread of the excitatory Gaussian for the audiotactile connections\n",
    "\n",
    "    av (int): strength of the excitatory Gaussian for the audiovisual connections\n",
    "    sigav (int): spread of the excitatory Gaussian for the audiovisual connections\n",
    "\n",
    "    vt (int): strength of the excitatory Gaussian for the visuotactile connections\n",
    "    sigvt (int): spread of the excitatory Gaussian for the visuootactile connections\n",
    "\n",
    "    Output:\n",
    "\n",
    "    Wat (4D.np.array): a MxN matrix of auditory neurons, each containing their connections to the MxN tactile neurons (i,j,:,:); or alternatively\n",
    "    a Mx N matrix of tactile neurons, each containing their connections to the MxN auditory neurons (:,:,i,j)\n",
    "    Wav (4D.np.array): a MxN matrix of visual neurons, each containing their connections to the MxN auditory neurons (i,j,:,:); or alternatively\n",
    "    a Mx N matrix of auditory neurons, each containing their connections to the MxN visual neurons (:,:,i,j)\n",
    "    Wvt (4D.np.array): a MxN matrix of visual neurons, each containing their connections to the MxN tactile neurons (i,j,:,:); or alternatively\n",
    "    a Mx N matrix of tactile neurons, each containing their connections to the MxN visual neurons (:,:,i,j)\n",
    "    \"\"\"\n",
    "\n",
    "    dx = xrfa.reshape(Ma, 1, 1, 1) - xrft.reshape(1, 1, Mt, 1)\n",
    "    dy = yrfa.reshape(1, Na, 1, 1) - yrft.reshape(1, 1, 1, Nt)\n",
    "    Wat = at * np.exp(-((np.square(dx) + np.square(dy)) / (2 * np.square(sigat))))\n",
    "\n",
    "    dx = xrfv.reshape(Mv, 1, 1, 1) - xrft.reshape(1, 1, Mt, 1)\n",
    "    dy = yrfv.reshape(1, Nv, 1, 1) - yrft.reshape(1, 1, 1, Nt)\n",
    "    Wvt = vt * np.exp(-((np.square(dx) + np.square(dy)) / (2 * np.square(sigvt))))\n",
    "\n",
    "    dx = xrfa.reshape(Ma, 1, 1, 1) - xrfv.reshape(1, 1, Mv, 1)\n",
    "    dy = yrfa.reshape(1, Na, 1, 1) - yrfv.reshape(1, 1, 1, Nv)\n",
    "    Wav = av * np.exp(-((np.square(dx) + np.square(dy)) / (2 * np.square(sigav))))\n",
    "\n",
    "    return Wat, Wvt, Wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e43c6",
   "metadata": {},
   "source": [
    "# Neural activity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural(qt, qa, qv, qm, Lt, La, Lv, zt, za, zv, Wat, Wvt, Wav, zm, Bt, Ba, Bv):\n",
    "    \"\"\"Compute the rates (z) as the sigmoid of the dynamic state variable\n",
    "\n",
    "    Input:\n",
    "        s (char): unimodality (a/t/v)\n",
    "        q (2D.np.array): state variable\n",
    "\n",
    "    Assumed Inputs:\n",
    "        fmin_t (int): lower boundary of the tactile sigmoid function\n",
    "        fmax_t (int): upper boundary of the tactile sigmoid function\n",
    "        qc_t (int): central point of the tactile sigmoid function\n",
    "        r_t (int): slope of the tactile sigmoid curve at the central point qc_t\n",
    "\n",
    "        fmin_a (int): lower boundary of the auditory sigmoid function\n",
    "        fmax_a (int): upper boundary of the auditory sigmoid function\n",
    "        qc_a (int): central point of the auditory sigmoid function\n",
    "        r_a (int): slope of the auditory sigmoid curve at the central point qc_a\n",
    "\n",
    "        fmin_m (int): lower boundary of the multisensory sigmoid function\n",
    "        fmax_m (int): upper boundary of the multisensory sigmoid function\n",
    "        qc_m (int): central point of the multisensory sigmoid function\n",
    "        r_m (int): slope of the multisensory sigmoid curve at the central point qc_m\n",
    "\n",
    "    Output:\n",
    "        psi (2D.np.array) the rates for the unimodality s\n",
    "    \"\"\"\n",
    "\n",
    "    # Cross-Modal Inputs\n",
    "\n",
    "    psit = (\n",
    "        np.ones((Mt, Nt)) * fmin_t\n",
    "        + fmax_t * np.exp((qt - np.ones((Mt, Nt)) * qc_t) * r_t)\n",
    "    ) / (np.ones((Mt, Nt)) + np.exp((qt - np.ones((Mt, Nt)) * qc_t) * r_t))\n",
    "    psia = (\n",
    "        np.ones((Ma, Na)) * fmin_a\n",
    "        + fmax_a * np.exp((qa - np.ones((Ma, Na)) * qc_a) * r_a)\n",
    "    ) / (np.ones((Ma, Na)) + np.exp((qa - np.ones((Ma, Na)) * qc_a) * r_a))\n",
    "    psiv = (\n",
    "        np.ones((Mv, Nv)) * fmin_v\n",
    "        + fmax_v * np.exp((qv - np.ones((Mv, Nv)) * qc_v) * r_v)\n",
    "    ) / (np.ones((Mv, Nv)) + np.exp((qv - np.ones((Mv, Nv)) * qc_v) * r_v))\n",
    "\n",
    "    psim = (fmin_m + fmax_m * np.exp((qm - qc_m) * r_m)) / (\n",
    "        1 + np.exp((qm - qc_m) * r_m)\n",
    "    )\n",
    "\n",
    "    LT = np.einsum(\"hkij, ij -> hk\", Lt, zt)\n",
    "    LA = np.einsum(\"hkij, ij -> hk\", La, za)\n",
    "    LV = np.einsum(\"hkij, ij -> hk\", Lv, zv)\n",
    "    AT = np.einsum(\"ijhk, ij -> hk\", Wat, za)\n",
    "    AV = np.einsum(\"ijhk, ij -> hk\", Wav, za)\n",
    "    VT = np.einsum(\"ijhk, ij -> hk\", Wvt, zv)\n",
    "    VA = np.einsum(\"hkij, ij -> hk\", Wav, zv)\n",
    "    TA = np.einsum(\"hkij, ij -> hk\", Wat, zt)\n",
    "    TV = np.einsum(\"hkij, ij -> hk\", Wvt, zt)\n",
    "\n",
    "    BT = np.multiply(Bt, zm)\n",
    "    BA = np.multiply(Ba, zm)\n",
    "    BV = np.multiply(Bv, zm)\n",
    "\n",
    "    return psit, psia, psiv, psim, LT, LA, LV, AT, AV, TA, TV, VT, VA, BT, BA, BV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ac961",
   "metadata": {},
   "source": [
    "# Evolutionary pruning mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a327f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built after Paredes et al., 2021\n",
    "\n",
    "\n",
    "def prun(WM, pr):\n",
    "    \"\"\"Computes synaptic pruning according to a fixed threshold rule.\n",
    "\n",
    "    Inout:\n",
    "        WM (2D np.array/4D.np.array): Feedforward/Cross-Modal synaptic weight matrix.\n",
    "        pr (number): Pruning threshold.\n",
    "\n",
    "    Output:\n",
    "        newM (2D np.array/4D.np.array): Pruned weight matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the original matrix\n",
    "    newM = np.copy(WM)\n",
    "\n",
    "    # Prune synaptic weights below the given threshold\n",
    "    newM[newM < pr] = 0\n",
    "\n",
    "    return newM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f545eaf",
   "metadata": {},
   "source": [
    "# Audio-tactile experiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    ts, T, dist, ya, Lt, La, Lv, Wt, Wa, Wv, Bt, Ba, Bv, Wat, Wvt, Wav, FWpr, CMpr\n",
    "):\n",
    "    \"\"\"Run a PPS-assessment simulation using the following parameters\n",
    "    Input:\n",
    "        ts (int): the discretising timestep of the Euler integration\n",
    "        T (int): the total simulation runtime\n",
    "        tau (int): time constant\n",
    "        dist (1D.np.array): vector of distance\n",
    "        ya (int): location on the y-axis of the auditory stimulus\n",
    "\n",
    "        Lt (4D.np.array): A matrix of shape (MxN) in which every ij position is another matrix of shape (MxN),\n",
    "                          in which every hk position details the lateral connectivity of ij with hk for the tactile region\n",
    "        La (4D.np.array): A matrix of shape (MxN) in which every ij position is another matrix of shape (MxN),\n",
    "                          in which every hk position details the lateral connectivity of ij with hk for the auditory region\n",
    "        Lv (4D.np.array): A matrix of shape (MxN) in which every ij position is another matrix of shape (MxN),\n",
    "                          in which every hk position details the lateral connectivity of ij with hk for the visual region\n",
    "\n",
    "        Wt (2D np.array): Feedforward synaptic weights in the tactile area.\n",
    "        Wa (2D np.array): Feedforward synaptic weights in the auditory area.\n",
    "        Wv (2D np.array): Feedforward synaptic weights in the visual area.\n",
    "\n",
    "        Bt (2D np.array): Feedback synaptic weights in the tactile area.\n",
    "        Ba (2D np.array): Feedback synaptic weights in the auditory area.\n",
    "        Bv (2D np.array): Feedback synaptic weights in the visual area\n",
    "\n",
    "        Wat (4D.np.array): a MxN matrix of auditory neurons, each containing their connections to the MxN tactile neurons (i,j,:,:); or alternatively\n",
    "        a Mx N matrix of tactile neurons, each containing their connections to the MxN auditory neurons (:,:,i,j)\n",
    "        Wav (4D.np.array): a MxN matrix of visual neurons, each containing their connections to the MxN auditory neurons (i,j,:,:); or alternatively\n",
    "        a Mx N matrix of auditory neurons, each containing their connections to the MxN visual neurons (:,:,i,j)\n",
    "        Wvt (4D.np.array): a MxN matrix of visual neurons, each containing their connections to the MxN tactile neurons (i,j,:,:); or alternatively\n",
    "        a Mx N matrix of tactile neurons, each containing their connections to the MxN visual neurons (:,:,i,j)\n",
    "\n",
    "    Output:\n",
    "        zt (4D.np.array): the activation values for the tactile region for each timestep given each auditory vertical distance\n",
    "        za (4D.np.array): the activation values for the auditory region for each timestep given each auditory vertical distance\n",
    "        zv (4D.np.array): the activation values for the visual region for each timestep given each auditory vertical distance\n",
    "        zm (2D.np.array): the activation values for the multisensory neuron for each timestep given each auditory vertical distance\n",
    "        RTs (1D.np.array): the reaction times for each given distance\n",
    "    \"\"\"\n",
    "    n = int(T / ts)  # number of iterations\n",
    "    tt = ts / tau\n",
    "    # Pruning of Connections\n",
    "\n",
    "    Wa = prun(Wa, FWpr)\n",
    "    Wv = prun(Wv, FWpr)\n",
    "\n",
    "    Wat = prun(Wat, CMpr)\n",
    "    Wvt = prun(Wvt, CMpr)\n",
    "    Wav = prun(Wav, CMpr)\n",
    "\n",
    "    ti = PHI_expt(\"t\", xt / 2, yt / 2)  # tactile stimuluis\n",
    "\n",
    "    qt = np.zeros((Mt, Nt, len(dist), n))\n",
    "    ut = np.zeros((Mt, Nt, len(dist), n))\n",
    "    zt = np.zeros((Mt, Nt, len(dist), n))\n",
    "\n",
    "    qa = np.zeros((Ma, Na, len(dist), n))\n",
    "    ua = np.zeros((Ma, Na, len(dist), n))\n",
    "    za = np.zeros((Ma, Na, len(dist), n))\n",
    "\n",
    "    qv = np.zeros((Mv, Nv, len(dist), n))\n",
    "    uv = np.zeros((Mv, Nv, len(dist), n))\n",
    "    zv = np.zeros((Mv, Nv, len(dist), n))\n",
    "\n",
    "    qm = np.zeros((len(dist), n))\n",
    "    um = np.zeros((len(dist), n))\n",
    "    zm = np.zeros((len(dist), n))\n",
    "\n",
    "    rt = np.zeros((len(dist), n))\n",
    "    RTs = np.zeros(len(dist))\n",
    "\n",
    "    for i in range(len(dist)):\n",
    "        ai = PHI_expa(\"a\", dist[i], ya)  # auditory stimulus\n",
    "        for j in range(1, n):\n",
    "            (\n",
    "                psit,\n",
    "                psia,\n",
    "                psiv,\n",
    "                psim,\n",
    "                LT,\n",
    "                LA,\n",
    "                LV,\n",
    "                AT,\n",
    "                AV,\n",
    "                TA,\n",
    "                TV,\n",
    "                VT,\n",
    "                VA,\n",
    "                BT,\n",
    "                BA,\n",
    "                BV,\n",
    "            ) = neural(\n",
    "                qt[:, :, i, j - 1],\n",
    "                qa[:, :, i, j - 1],\n",
    "                qv[:, :, i, j - 1],\n",
    "                qm[i, j - 1],\n",
    "                Lt,\n",
    "                La,\n",
    "                Lv,\n",
    "                zt[:, :, i, j - 1],\n",
    "                za[:, :, i, j - 1],\n",
    "                zv[:, :, i, j - 1],\n",
    "                Wat,\n",
    "                Wvt,\n",
    "                Wav,\n",
    "                zm[i, j - 1],\n",
    "                Bt,\n",
    "                Ba,\n",
    "                Bv,\n",
    "            )\n",
    "\n",
    "            ut[:, :, i, j] = ti + LT + BT + AT + VT\n",
    "            qt[:, :, i, j] = qt[:, :, i, j - 1] + tt * (\n",
    "                -qt[:, :, i, j - 1] + ut[:, :, i, j - 1]\n",
    "            )\n",
    "            zt[:, :, i, j] = np.maximum(psit, 0)  # heaviside function\n",
    "\n",
    "            ua[:, :, i, j] = ai + LA + BA + TA + VA\n",
    "            qa[:, :, i, j] = qa[:, :, i, j - 1] + tt * (\n",
    "                -qa[:, :, i, j - 1] + ua[:, :, i, j - 1]\n",
    "            )\n",
    "            za[:, :, i, j] = np.maximum(psia, 0)  # heaviside function\n",
    "\n",
    "            uv[:, :, i, j] = LV + BV + TV + AV\n",
    "            qv[:, :, i, j] = qv[:, :, i, j - 1] + tt * (\n",
    "                -qv[:, :, i, j - 1] + uv[:, :, i, j - 1]\n",
    "            )\n",
    "            zv[:, :, i, j] = np.maximum(psiv, 0)  # heaviside function\n",
    "\n",
    "            um[i, j] = (\n",
    "                np.einsum(\"ij, ij -> \", Wt, zt[:, :, i, j - 1])\n",
    "                + np.einsum(\"ij, ij -> \", Wa, za[:, :, i, j - 1])\n",
    "                + np.einsum(\"ij, ij -> \", Wv, zv[:, :, i, j - 1])\n",
    "            )\n",
    "            qm[i, j] = qm[i, j - 1] + tt * (-qm[i, j - 1] + um[i, j - 1])\n",
    "            zm[i, j] = np.maximum(psim, 0)  # heaviside function\n",
    "\n",
    "            rt[i, j] = np.any(zt[:, :, i, j - 1] > (0.9))\n",
    "\n",
    "        # Compute the RT for this distance\n",
    "\n",
    "        RTs[i] = np.argmax(rt[i, :]) * ts  # * 3 + 60\n",
    "\n",
    "    return zt, za, zm, zv, RTs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eca1d15c",
   "metadata": {},
   "source": [
    "# Training Input Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4c4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stim_tr(s, x, y, x0, y0, sigav_x):\n",
    "    \"\"\"Compute the training stimuli for one point for modality s (a/t/v)\n",
    "\n",
    "    Input:\n",
    "    s (char): the modality (auditory/tactile/visual)\n",
    "    x (int): x coordinate\n",
    "    y (int): y coordinate\n",
    "\n",
    "    Output:\n",
    "\n",
    "    I (int): the stimulus intensity\n",
    "    \"\"\"\n",
    "\n",
    "    sigax_tr = sigav_x\n",
    "    sigvx_tr = sigav_x\n",
    "\n",
    "    if s == \"t\":\n",
    "        # if ((3 < y < 7) and ((5 < x < 10))): I = It_0_tr\n",
    "        # else: I = 0\n",
    "        I = (It_0_tr + signoiset_t * np.random.randn()) * np.exp(\n",
    "            -((np.square(x0 - x)) / (2 * np.square(sigtx_tr)))\n",
    "            - ((np.square(y0 - y)) / (2 * np.square(sigty_tr)))\n",
    "        )\n",
    "\n",
    "    elif s == \"a\":\n",
    "        I = (Ia_0_tr + signoiset_a * np.random.randn()) * np.exp(\n",
    "            -((np.square(x0 - x)) / (2 * np.square(sigax_tr)))\n",
    "            - ((np.square(y0 - y)) / (2 * np.square(sigay_tr)))\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        I = (Iv_0_tr + signoiset_v * np.random.randn()) * np.exp(\n",
    "            -((np.square(x0 - x)) / (2 * np.square(sigvx_tr)))\n",
    "            - ((np.square(y0 - y)) / (2 * np.square(sigvy_tr)))\n",
    "        )\n",
    "\n",
    "    return I\n",
    "\n",
    "\n",
    "def stimspace_tr(s, x0, y0, sigav_x):\n",
    "    \"\"\"Compute the stimulus intensity for the unimodal space s (t/a) for a stimulus centered around x0 and y0\n",
    "\n",
    "    Input:\n",
    "        s  (char): region of stimulation (tactile/auditory)\n",
    "        x0 (int): vertical center of stimulus\n",
    "        y0 (int): horizontal center of stimulus\n",
    "\n",
    "    Output:\n",
    "        v (2D.np.array): matrix of stimulus intensity for the entire unimodal space\n",
    "    \"\"\"\n",
    "\n",
    "    sigax_tr = sigav_x\n",
    "    sigvx_tr = sigav_x\n",
    "    sigtx_tr = sigav_x\n",
    "\n",
    "    if s == \"t\":\n",
    "        v = np.zeros((int(xt / dx + 1), int(yt / dy + 1)))\n",
    "        for x in range(int(xt / dx + 1)):\n",
    "            for y in range(int(yt / dy + 1)):\n",
    "                v[x, y] = stim_tr(\"t\", x * dx, y * dy, x0, y0, sigtx_tr)\n",
    "\n",
    "    elif s == \"a\":\n",
    "        v = np.zeros((int(xa / dx + 1), int(ya / dy + 1)))\n",
    "        for x in range(int(xa / dy + 1)):\n",
    "            for y in range(int(ya / dy + 1)):\n",
    "                v[x, y] = stim_tr(\"a\", x * dx, y * dy, x0, y0, sigax_tr)\n",
    "    else:\n",
    "        v = np.zeros((int(xv / dx + 1), int(yv / dy + 1)))\n",
    "        for x in range(int(xv / dy + 1)):\n",
    "            for y in range(int(yv / dy + 1)):\n",
    "                v[x, y] = stim_tr(\"v\", x * dx, y * dy, x0, y0, sigvx_tr)\n",
    "\n",
    "    return v\n",
    "\n",
    "\n",
    "def PHI_tr(s, x0, y0, sigav_x):\n",
    "    \"\"\"This function computes the external input to the unimodal area \"s\" based on a stimulus centered around x0 and y0\n",
    "    Input:\n",
    "        s (char): unimodality (a/t)\n",
    "        x0 (int): center of the external stimulus on the x axis\n",
    "        y0 (int): center of the external stimulus on the y axis\n",
    "\n",
    "    Assumed Inputs:\n",
    "        Phit (4D.np.array): a matrix of each tactile neuron's receptive field\n",
    "        Phia (4D.np.array): a matrix of each auditory neuron's receptive field\n",
    "    \"\"\"\n",
    "\n",
    "    if s == \"t\":\n",
    "        Phi = Phit\n",
    "    elif s == \"a\":\n",
    "        Phi = Phia\n",
    "    else:\n",
    "        Phi = Phiv\n",
    "\n",
    "    PHI = np.multiply(Phi, stimspace_tr(s, x0, y0, sigav_x))\n",
    "\n",
    "    PHI = np.sum(PHI, axis=3)\n",
    "    PHI = np.sum(PHI, axis=2)\n",
    "\n",
    "    return PHI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "840a200b",
   "metadata": {},
   "source": [
    "# Auditory - Visual - Tactile Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 total movements, so 100 network presentations?\n",
    "\n",
    "\n",
    "def FWTraining(\n",
    "    m,\n",
    "    T,\n",
    "    ts,\n",
    "    Lt,\n",
    "    La,\n",
    "    Lv,\n",
    "    Wt,\n",
    "    Wa,\n",
    "    Wv,\n",
    "    Bt,\n",
    "    Ba,\n",
    "    Bv,\n",
    "    Wat,\n",
    "    Wvt,\n",
    "    Wav,\n",
    "    FWpr,\n",
    "    rho_0,\n",
    "    Wmax_a,\n",
    "    Wmax_v,\n",
    "    k_v,\n",
    "    k_a,\n",
    "    theta,\n",
    "    sigav_x,\n",
    "    locav_x,\n",
    "):\n",
    "    \"\"\"Train the feedforward auditory and visual weights\n",
    "\n",
    "    Input:\n",
    "\n",
    "        stcount (int): number of presentations\n",
    "        T (int): simulation steps (ms)\n",
    "        ts (int): timestep\n",
    "\n",
    "        Lt (4D.np.array): tactile lateral connections\n",
    "        La (4D.np.array): auditory lateral connections\n",
    "        Lv (4D.np.array): visual lateral connections\n",
    "        Wt (2D.np.array): feedforward tactile connections\n",
    "        Wa (2D.np.array): feedforward auditory connections\n",
    "        Wv (2D.np.array): feedforward visual connections\n",
    "        Bt (2D.np.array): feedback tactile connections\n",
    "        Ba (2D.np.array): feedback auditory connections\n",
    "        Bv (2D.np.array): feedback visual connections\n",
    "\n",
    "        rho_0 (int): reinforcing factor\n",
    "        Wmax_a (int): maximum value for auditory weights\n",
    "        Wmax_v (int): maximum value for visual weights\n",
    "        k_a (int): auditory forgetting factor\n",
    "        k_v (int): visual forgetting factor\n",
    "        theta (int): multisensory neuron activation thrseshold\n",
    "\n",
    "    Output:\n",
    "        Wa_tr (4D.np.array): feedfoward auditory connections for the snychronous condition\n",
    "        Wv_tr (4D.np.array): feedfoward visual connections for the snychronous condition\n",
    "    \"\"\"\n",
    "    # Initialise Weights // initially, they start off with the predefined feedforward weights // AS - Asynchronous, S - Synchronous\n",
    "\n",
    "    n = int(T / ts)\n",
    "    tt = ts / tau\n",
    "\n",
    "    Wa = prun(Wa, FWpr)\n",
    "    Wv = prun(Wv, FWpr)\n",
    "\n",
    "    Wa_tr = np.zeros((Ma, Na, m, n))\n",
    "    Wv_tr = np.zeros((Mv, Nv, m, n))\n",
    "\n",
    "    Wa_tr[:, :, 0, 0] = Wa\n",
    "    Wv_tr[:, :, 0, 0] = Wv\n",
    "\n",
    "    qt = np.zeros((Mt, Nt, m, n))\n",
    "    ut = np.zeros((Mt, Nt, m, n))\n",
    "    zt = np.zeros((Mt, Nt, m, n))\n",
    "\n",
    "    qa = np.zeros((Ma, Na, m, n))\n",
    "    ua = np.zeros((Ma, Na, m, n))\n",
    "    za = np.zeros((Ma, Na, m, n))\n",
    "\n",
    "    qv = np.zeros((Mv, Nv, m, n))\n",
    "    uv = np.zeros((Mv, Nv, m, n))\n",
    "    zv = np.zeros((Mv, Nv, m, n))\n",
    "\n",
    "    qm = np.zeros((m, n))\n",
    "    um = np.zeros((m, n))\n",
    "    zm = np.zeros((m, n))\n",
    "\n",
    "    ti = PHI_tr(\"t\", 10, 5, sigav_x)  # tactile stimulus\n",
    "    ai = PHI_tr(\"a\", locav_x, 5, sigav_x)  # auditory stimulus\n",
    "    vi = PHI_tr(\"v\", locav_x, 5, sigav_x)  # visual stimulus\n",
    "\n",
    "    for i in range(m):\n",
    "        # Intialise weights, either to the predefined ones, or to the ones from the previous simulation\n",
    "        if i != 0:\n",
    "            Wa_tr[:, :, i, 0] = Wa_tr[:, :, i - 1, -1]\n",
    "            Wv_tr[:, :, i, 0] = Wv_tr[:, :, i - 1, -1]\n",
    "\n",
    "        for j in range(1, n):\n",
    "            (\n",
    "                psit,\n",
    "                psia,\n",
    "                psiv,\n",
    "                psim,\n",
    "                LT,\n",
    "                LA,\n",
    "                LV,\n",
    "                AT,\n",
    "                AV,\n",
    "                TA,\n",
    "                TV,\n",
    "                VT,\n",
    "                VA,\n",
    "                BT,\n",
    "                BA,\n",
    "                BV,\n",
    "            ) = neural(\n",
    "                qt[:, :, i, j - 1],\n",
    "                qa[:, :, i, j - 1],\n",
    "                qv[:, :, i, j - 1],\n",
    "                qm[i, j - 1],\n",
    "                Lt,\n",
    "                La,\n",
    "                Lv,\n",
    "                zt[:, :, i, j - 1],\n",
    "                za[:, :, i, j - 1],\n",
    "                zv[:, :, i, j - 1],\n",
    "                Wat,\n",
    "                Wvt,\n",
    "                Wav,\n",
    "                zm[i, j - 1],\n",
    "                Bt,\n",
    "                Ba,\n",
    "                Bv,\n",
    "            )\n",
    "\n",
    "            ut[:, :, i, j] = ti + LT + BT + AT + VT\n",
    "            qt[:, :, i, j] = qt[:, :, i, j - 1] + tt * (\n",
    "                -qt[:, :, i, j - 1] + ut[:, :, i, j - 1]\n",
    "            )\n",
    "            zt[:, :, i, j] = np.maximum(psit, 0)  # heaviside function\n",
    "\n",
    "            ua[:, :, i, j] = ai + LA + BA + TA + VA\n",
    "            qa[:, :, i, j] = qa[:, :, i, j - 1] + tt * (\n",
    "                -qa[:, :, i, j - 1] + ua[:, :, i, j - 1]\n",
    "            )\n",
    "            za[:, :, i, j] = np.maximum(psia, 0)  # heaviside function\n",
    "\n",
    "            uv[:, :, i, j] = vi + LV + BV + AV + TV\n",
    "            qv[:, :, i, j] = qv[:, :, i, j - 1] + tt * (\n",
    "                -qv[:, :, i, j - 1] + uv[:, :, i, j - 1]\n",
    "            )\n",
    "            zv[:, :, i, j] = np.maximum(psiv, 0)  # heaviside function\n",
    "\n",
    "            qm[i, j] = qm[i, j - 1] + tt * (-qm[i, j - 1] + um[i, j - 1])\n",
    "            um[i, j] = (\n",
    "                np.einsum(\"ij, ij -> \", Wt, zt[:, :, i, j - 1])\n",
    "                + np.einsum(\"ij, ij -> \", Wa_tr[:, :, i, j - 1], za[:, :, i, j - 1])\n",
    "                + np.einsum(\"ij, ij -> \", Wv_tr[:, :, i, j - 1], zv[:, :, i, j - 1])\n",
    "            )\n",
    "            zm[i, j] = np.maximum(psim, 0)  # heaviside function\n",
    "\n",
    "            # Auditory Feedforward Training\n",
    "            dWa = (rho_0 * (Wmax_a - Wa_tr[:, :, i, j - 1])) * za[\n",
    "                :, :, i, j - 1\n",
    "            ] * np.maximum((zm[i, j - 1] - theta), 0) - k_a * np.maximum(\n",
    "                (zm[i, j - 1] - theta), 0\n",
    "            ) * (\n",
    "                Wa_tr[:, :, i, j - 1] - Wa_tr[:, :, 0, 0]\n",
    "            )\n",
    "            Wa_tr[:, :, i, j] = Wa_tr[:, :, i, j - 1] + dWa\n",
    "\n",
    "            # Visual Feedforward Training\n",
    "            dWv = (rho_0 * (Wmax_v - Wv_tr[:, :, i, j - 1])) * zv[\n",
    "                :, :, i, j - 1\n",
    "            ] * np.maximum((zm[i, j - 1] - theta), 0) - k_v * np.maximum(\n",
    "                (zm[i, j - 1] - theta), 0\n",
    "            ) * (\n",
    "                Wv_tr[:, :, i, j - 1] - Wv_tr[:, :, 0, 0]\n",
    "            )\n",
    "            Wv_tr[:, :, i, j] = Wv_tr[:, :, i, j - 1] + dWv\n",
    "\n",
    "            # Tactile Training\n",
    "            # dW_t = (rho_0 * (Wmax_t - WS_t[:,:, i, j - 1])) * zt[:,:,i, j - 1] * (zm[i,j-1] - theta) * np.heaviside((zm[i,j-1] - theta), 0) - k_t * (zm[i,j-1] - theta) * np.heaviside((zm[i,j-1] - theta), 0) *(WS_t[:,:, i, j - 1] - WS_t[:,:, i, 0])\n",
    "            # WS_t[:,:,i,j] = WS_t[:,:,i,j - 1] + dW_t\n",
    "\n",
    "    return Wa_tr, Wv_tr, zm, zv, za, zt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c950d1",
   "metadata": {},
   "source": [
    "# Sigmoid fitting functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RTsig(distances, cp, slope):\n",
    "    \"\"\"Compute the sigmoidal function\n",
    "    Input:\n",
    "        disances (1D.np.array): vector of distances\n",
    "        cp (int): central point of the curve\n",
    "        slope (int): slope of the curve\n",
    "    Output:\n",
    "        sig (1D.np.array): the appropriate y-values for distances as x-values\n",
    "    \"\"\"\n",
    "    global ymin\n",
    "    global ymax\n",
    "\n",
    "    sig = (ymin + ymax * np.exp((distances - cp) / slope)) / (\n",
    "        1 + np.exp((distances - cp) / slope)\n",
    "    )\n",
    "\n",
    "    return sig\n",
    "\n",
    "\n",
    "def fitting(distances, RTs):\n",
    "    \"\"\"Fit the sigmoidal curve to get the cp and slope\n",
    "\n",
    "    Input:\n",
    "        distances (1D.np.array): vector of distances\n",
    "        RTs (1D.np.array): vector of reaction times\n",
    "\n",
    "    Output:\n",
    "        cp (int): central point of the sigmoid\n",
    "        slope (int): slope of the sigmoid\n",
    "    \"\"\"\n",
    "\n",
    "    global ymin\n",
    "    global ymax\n",
    "\n",
    "    # Defines starting points and boundaries for the fitting\n",
    "    k_0 = (ymax - ymin) / (distances[-1] - distances[0])\n",
    "\n",
    "    initial_slope = (ymax - ymin) / (4 * k_0)\n",
    "    middle_distance = np.max(distances) / 2\n",
    "\n",
    "    init_guess = [middle_distance, initial_slope]\n",
    "    boundaries = ([0, float(\"-inf\")], [float(\"inf\"), float(\"inf\")])\n",
    "\n",
    "    # Fits the data\n",
    "    popt, pcov = curve_fit(\n",
    "        RTsig,\n",
    "        xdata=distances,\n",
    "        ydata=RTs,\n",
    "        p0=init_guess,\n",
    "        method=\"trf\",\n",
    "        ftol=1e-8,\n",
    "        xtol=1e-8,\n",
    "        maxfev=10000,\n",
    "        bounds=boundaries,\n",
    "    )\n",
    "    sigpar = np.asarray(popt)\n",
    "\n",
    "    cp = sigpar[0]\n",
    "    slope = sigpar[1]\n",
    "\n",
    "    return cp, slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RT fitting\n",
    "\n",
    "\n",
    "def fit_RT(xf, yf):\n",
    "    m = (xf.size * np.sum(xf * yf) - np.sum(xf) * np.sum(yf)) / (\n",
    "        xf.size * np.sum(xf * xf) - np.sum(xf) ** 2\n",
    "    )\n",
    "    bias = (np.sum(yf) - m * np.sum(xf)) / xf.size\n",
    "\n",
    "    if bias < 0:\n",
    "        bias = 0\n",
    "    if m < 0:\n",
    "        m = 0\n",
    "\n",
    "    return m * xf + bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e721ae0",
   "metadata": {},
   "source": [
    "# Spearman-Karber Fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da41177a",
   "metadata": {},
   "source": [
    "### Monotonization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944af8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monotonize(fi, nTrials):\n",
    "    fiMono = np.copy(fi)\n",
    "\n",
    "    while not np.all(np.diff(fiMono) >= 0):  # while non monotonic\n",
    "        i = 0\n",
    "        while i < len(fiMono) - 1:\n",
    "            if fiMono[i] <= fiMono[i + 1]:\n",
    "                i += 1\n",
    "\n",
    "            else:\n",
    "                k = 0\n",
    "                while True:\n",
    "                    tempfi = np.sum(\n",
    "                        fiMono[i : i + k + 1] * nTrials[i : i + k + 1]\n",
    "                    ) / np.sum(nTrials[i : i + k + 1])\n",
    "                    if i + k > len(fiMono):\n",
    "                        break\n",
    "                    elif fiMono[i + k] > tempfi:\n",
    "                        break\n",
    "                    else:\n",
    "                        k += 1\n",
    "\n",
    "                fiMono[i : i + k + 1] = np.ones(k + 1) * tempfi\n",
    "                i = i + k + 1\n",
    "\n",
    "    return fiMono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a3ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fise(fi):\n",
    "    fi = (fi - np.min(fi)) / (np.max(fi) - np.min(fi))\n",
    "    return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SK(fi, dist, nTrials):\n",
    "    DLc = 0.6745\n",
    "    # 75th percentile of standard normal\n",
    "    s = 500\n",
    "\n",
    "    fis = fise(fi)  # turn into probs\n",
    "    fim = monotonize(fis, nTrials)\n",
    "    fi = np.append(0, fim)\n",
    "    fi = np.append(fi, 1)\n",
    "    fi = np.diff(fi)\n",
    "\n",
    "    distsq = np.square(dist)\n",
    "    distcube = np.power(dist, 3)\n",
    "\n",
    "    PSE = 1 / 2 * np.sum(fi * np.diff(distsq) / np.diff(dist))\n",
    "    M = 1 / 3 * np.sum(fi * np.diff(distcube) / np.diff(dist))\n",
    "    sigSK = np.sqrt(M - PSE**2)\n",
    "    DL = sigSK * DLc\n",
    "    CE = PSE - s\n",
    "\n",
    "    return PSE, M, sigSK, DL, CE, fim, fis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1359 PSE pre, 504 DL pre play around\n",
    "# fi = [283.467, 283.761, 303.932, 325.895, 329.403]\n",
    "#\n",
    "# s_dist= [3200, 2700, 2200, 1500, 800, 300, -200]\n",
    "# a_dist = [126, 111, 96, 75, 54, 39, 24]\n",
    "# SK(fi, a_dist, [1,1,1,1,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa3a3dc5",
   "metadata": {},
   "source": [
    "# Behavioural Parameters From Ferroni et al., 2022 and Di Cosmo et al., 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b45ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ferroni et al., 2022\n",
    "# Sigmoidal Parameters\n",
    "\n",
    "##Pre-Training\n",
    "###Healthy Controls\n",
    "fprHCCP = 120 - 1.377 * 30\n",
    "fprHCS = 1 / 0.11\n",
    "###Schizophrenia\n",
    "fprSCZCP = 120 - 1.666 * 30\n",
    "fprSCZS = 1 / 0.075\n",
    "\n",
    "##Post Training\n",
    "###Healthy Controls\n",
    "fpostHCCP = 120 - 1.028 * 30\n",
    "fpostHCS = 1 / 0.18\n",
    "###Schizophrenia\n",
    "fpostSCZCP = 120 - 1.361 * 30\n",
    "fpostSCZS = 1 / 0.061\n",
    "\n",
    "\n",
    "# Spearman-Kaerber Parameters\n",
    "\n",
    "##Pre-Training\n",
    "###Healthy Controls\n",
    "fprHCPSE = 120 - 1.359 * 30\n",
    "fprHCDL = ...  # 504\n",
    "###Schizophrenia\n",
    "fprSCZPSE = 120 - 1.504 * 30\n",
    "fprSCZDL = ...  # 696\n",
    "\n",
    "##Post Training\n",
    "###Healthy Controls\n",
    "fpostHCPSE = 120 - 1.254 * 30\n",
    "fpostHCDL = ...  # 540\n",
    "###Schizophrenia\n",
    "fpostSCZPSE = 120 - 1.405 * 30\n",
    "fpostSCZDL = ...  # 613\n",
    "\n",
    "# Di Cosmo et al., 2018\n",
    "\n",
    "dcSCZCP = 120 - 1.654 * 30\n",
    "dcSCZS = 1 / 0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpreHCRTSig = [279.747, 277.283, 301.396, 326, 331]\n",
    "import numpy as np\n",
    "\n",
    "fpostHCRTSig = [\n",
    "    334.900769230769,\n",
    "    304.051538461538,\n",
    "    283.203846153846,\n",
    "    277.339230769231,\n",
    "    277.027692307692,\n",
    "][::-1]\n",
    "\n",
    "fpreSRTSig = [\n",
    "    402.582380952381,\n",
    "    409.355714285714,\n",
    "    391.851904761905,\n",
    "    375.072380952381,\n",
    "    366.409523809524,\n",
    "][::-1]\n",
    "fpostSRTSig = [\n",
    "    425.620952380952,\n",
    "    404.887142857143,\n",
    "    378.611428571428,\n",
    "    368.370952380952,\n",
    "    384.501904761905,\n",
    "][::-1]\n",
    "\n",
    "fpreHCRTSK = [283, 329, 337, 304, 284][::-1]\n",
    "fpreHCRTSK = (fpreHCRTSK - np.min(fpreHCRTSK)) / (\n",
    "    np.max(fpreHCRTSK) - np.min(fpreHCRTSK)\n",
    ")\n",
    "fpreSRTSK = [\n",
    "    380.642229577875,\n",
    "    397.821818801943,\n",
    "    412.798365471543,\n",
    "    394.017373770684,\n",
    "    391.223527385707,\n",
    "][::-1]\n",
    "fpreSRTSK = (fpreSRTSK - np.min(fpreSRTSK)) / (np.max(fpreSRTSK) - np.min(fpreSRTSK))\n",
    "\n",
    "\n",
    "fpostHCRTSK = [280, 336, 313, 291, 280][::-1]\n",
    "fpostHCRTSK = (fpostHCRTSK - np.min(fpostHCRTSK)) / (\n",
    "    np.max(fpostHCRTSK) - np.min(fpostHCRTSK)\n",
    ")\n",
    "fpostSRTSK = [\n",
    "    389.654637856702,\n",
    "    424.157148212331,\n",
    "    401.931595742975,\n",
    "    384.72284079883,\n",
    "    383.285761190903,\n",
    "][::-1]\n",
    "fpostSRTSK = (fpostSRTSK - np.min(fpostSRTSK)) / (\n",
    "    np.max(fpostSRTSK) - np.min(fpostSRTSK)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5288b1",
   "metadata": {},
   "source": [
    "Bibliography:\n",
    "\n",
    "Paredes, R., Ferri, F., & Seriès, P. (2022). Influence of E/I balance and pruning in peri-personal space differences in schizophrenia: a computational approach. Schizophrenia Research, 248, 368-377.\n",
    "\n",
    "Serino, A., Canzoneri, E., Marzolla, M., Di Pellegrino, G., & Magosso, E. (2015). Extending peripersonal space representation without tool-use: evidence from a combined behavioral-computational approach. Frontiers in behavioral neuroscience, 9, 4.\n",
    "\n",
    "Magosso, E., Ursino, M., di Pellegrino, G., Làdavas, E., & Serino, A. (2010). Neural bases of peri-hand space plasticity through tool-use: Insights from a combined computational–experimental approach. Neuropsychologia, 48(3), 812-830."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
